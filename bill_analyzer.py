"""
ä¿¡ç”¨å¡å¸³å–®åˆ†æå™¨ - æ”¹é€²ç‰ˆ
æ¡ç”¨ç¬¬ä¸€ä»½ä»£ç¢¼çš„æˆåŠŸç­–ç•¥ï¼šç°¡æ½” prompt + é‡è©¦æ©Ÿåˆ¶ + Gemini 2.5
"""

import os
import json
import base64
import requests
import PyPDF2
import fitz  # PyMuPDF
from PIL import Image
import io
import logging
import time
from datetime import datetime
import re
import tempfile

class BillAnalyzer:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.setup_apis()
        
        # è™•ç†è¨­å®š
        self.settings = {
            "dpi": 300,
            "remove_last_page": True,
        }
        
        # éŠ€è¡Œè­˜åˆ¥è¦å‰‡
        self.bank_patterns = {
            "æ˜Ÿå±•éŠ€è¡Œ": ["æ˜Ÿå±•", "DBS", "DBS Bank", "DBS BANK"],
            "å°æ–°éŠ€è¡Œ": ["å°æ–°", "TAISHIN", "å°æ–°éŠ€è¡Œ", "TAISHIN BANK"],
            "æ°¸è±éŠ€è¡Œ": ["æ°¸è±", "SinoPac", "æ°¸è±éŠ€è¡Œ", "SINOPAC"],
            "åœ‹æ³°ä¸–è¯": ["åœ‹æ³°", "CATHAY", "åœ‹æ³°ä¸–è¯", "CATHAY UNITED BANK"],
            "è¯é‚¦éŠ€è¡Œ": ["è¯é‚¦", "UNION", "è¯é‚¦éŠ€è¡Œ", "UNION BANK"]
        }
    
    def setup_apis(self):
        """è¨­å®šå„ç¨® API"""
        try:
            # Google Vision API
            self.vision_api_key = os.getenv('GOOGLE_CLOUD_VISION_API_KEY')
            if not self.vision_api_key:
                raise ValueError("GOOGLE_CLOUD_VISION_API_KEY not found")
            
            # Gemini API
            self.gemini_api_key = os.getenv('GEMINI_API_KEY')
            if not self.gemini_api_key:
                raise ValueError("GEMINI_API_KEY not found")
            
            self.logger.info("API è¨­å®šå®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"API è¨­å®šå¤±æ•—: {e}")
            raise
    
    def analyze_pdf(self, pdf_content, bank_config, filename):
        """
        åˆ†æ PDF å¸³å–®çš„å®Œæ•´æµç¨‹
        
        Args:
            pdf_content: PDF æª”æ¡ˆå…§å®¹ (bytes)
            bank_config: éŠ€è¡Œè¨­å®šè³‡è¨Š
            filename: æª”æ¡ˆåç¨±
            
        Returns:
            dict: åˆ†æçµæœï¼ŒåŒ…å« success å’Œ data æˆ– error
        """
        self.logger.info(f"é–‹å§‹åˆ†æå¸³å–®: {filename}")
        
        temp_pdf_path = None
        temp_image_paths = []
        
        try:
            # 1. å„²å­˜ PDF åˆ°æš«å­˜æª”æ¡ˆ
            temp_pdf_path = self.save_temp_pdf(pdf_content, filename)
            if not temp_pdf_path:
                raise Exception("å„²å­˜æš«å­˜ PDF å¤±æ•—")
            
            # 2. PDF è½‰åœ–ç‰‡
            temp_image_paths = self.pdf_to_images(temp_pdf_path, bank_config.get('password', ''))
            if not temp_image_paths:
                raise Exception("PDF è½‰åœ–ç‰‡å¤±æ•—")
            
            # 3. OCR è™•ç†
            ocr_results = []
            for idx, image_path in enumerate(temp_image_paths):
                self.logger.info(f"è™•ç†ç¬¬ {idx + 1}/{len(temp_image_paths)} é ")
                ocr_result = self.ocr_with_vision_api(image_path)
                if ocr_result:
                    ocr_results.append(ocr_result)
            
            if not ocr_results:
                raise Exception("OCR è™•ç†å¤±æ•—")
            
            # 4. è™•ç† OCR çµæœ - æ¡ç”¨åº§æ¨™é‡çµ„æ–¹å¼
            processed_text = self.process_ocr_with_coordinates(ocr_results)
            if not processed_text:
                raise Exception("æ–‡å­—è™•ç†å¤±æ•—")
            
            # 5. æ¸…ç†ä¸­æ–‡ç©ºæ ¼
            cleaned_text = self.clean_chinese_spacing(processed_text)
            
            self.logger.info(f"OCR è™•ç†å®Œæˆï¼Œæ–‡å­—é•·åº¦: {len(cleaned_text)} å­—å…ƒ")
            
            # 6. è­˜åˆ¥æ–‡ä»¶é¡å‹
            document_type = self.identify_document_type(cleaned_text, filename)
            
            # 7. è­˜åˆ¥éŠ€è¡Œ
            bank_name = bank_config.get('name', '') or self.identify_bank(cleaned_text)
            
            # ğŸ†• 8. æ ¹æ“šæ–‡å­—é•·åº¦æ±ºå®šåˆ†æç­–ç•¥
            if len(cleaned_text) > 20000:
                self.logger.warning(f"æ–‡å­—éé•· ({len(cleaned_text)} å­—å…ƒ)ï¼Œæ¡ç”¨åˆ†é åˆ†æç­–ç•¥")
                analysis_result = self.analyze_by_pages(ocr_results, bank_name, document_type)
            else:
                # 8. LLM åˆ†æï¼ˆæ¡ç”¨ç¬¬ä¸€ä»½ä»£ç¢¼çš„ç­–ç•¥ï¼‰
                analysis_result = self.gemini_analyze(cleaned_text, bank_name, document_type)
            
            if not analysis_result:
                raise Exception("LLM åˆ†æå¤±æ•—")
            
            self.logger.info(f"âœ… å¸³å–®åˆ†ææˆåŠŸ: {filename}")
            return {
                'success': True,
                'data': {
                    'document_type': document_type,
                    'bank_name': bank_name,
                    'analysis_result': analysis_result,
                    'raw_text_length': len(cleaned_text)
                }
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å¸³å–®åˆ†æå¤±æ•— {filename}: {e}")
            return {
                'success': False,
                'error': str(e)
            }
            
        finally:
            # æ¸…ç†æš«å­˜æª”æ¡ˆ
            self.cleanup_temp_files([temp_pdf_path] + temp_image_paths)
    
    def save_temp_pdf(self, pdf_content, filename):
        """å°‡ PDF å…§å®¹å„²å­˜åˆ°æš«å­˜æª”æ¡ˆ"""
        try:
            temp_dir = tempfile.gettempdir()
            temp_path = os.path.join(temp_dir, f"temp_{filename}")
            
            with open(temp_path, 'wb') as f:
                f.write(pdf_content)
            
            self.logger.info(f"PDF å„²å­˜åˆ°æš«å­˜æª”æ¡ˆ: {temp_path}")
            return temp_path
            
        except Exception as e:
            self.logger.error(f"å„²å­˜æš«å­˜ PDF å¤±æ•—: {e}")
            return None
    
    def pdf_to_images(self, pdf_path, password=""):
        """å°‡PDFè½‰æ›æˆåœ–ç‰‡"""
        try:
            self.logger.info(f"é–‹å§‹è½‰æ› PDF: {pdf_path}")
            
            pdf_document = fitz.open(pdf_path)
            
            if pdf_document.needs_pass:
                if not pdf_document.authenticate(password):
                    raise Exception("PDF å¯†ç¢¼éŒ¯èª¤")
                self.logger.info("PDF è§£é–æˆåŠŸ")
            
            images = []
            page_count = pdf_document.page_count
            
            # æ±ºå®šè¦è™•ç†çš„é é¢ç¯„åœï¼ˆç§»é™¤æœ€å¾Œä¸€é ï¼‰
            end_page = page_count - 1 if self.settings["remove_last_page"] and page_count > 1 else page_count
            
            self.logger.info(f"PDF å…± {page_count} é ï¼Œè™•ç†å‰ {end_page} é ")
            
            temp_dir = tempfile.gettempdir()
            for page_num in range(end_page):
                page = pdf_document[page_num]
                mat = fitz.Matrix(self.settings["dpi"]/72, self.settings["dpi"]/72)
                pix = page.get_pixmap(matrix=mat)
                
                img_data = pix.tobytes("png")
                image = Image.open(io.BytesIO(img_data))
                
                temp_path = os.path.join(temp_dir, f"page_{page_num + 1}_{datetime.now().timestamp()}.png")
                image.save(temp_path, "PNG", quality=95)
                images.append(temp_path)
                
                self.logger.info(f"é é¢ {page_num + 1} è½‰æ›å®Œæˆ")
            
            pdf_document.close()
            self.logger.info(f"PDF è½‰åœ–ç‰‡å®Œæˆï¼Œå…± {len(images)} å¼µ")
            return images
            
        except Exception as e:
            self.logger.error(f"PDF è½‰åœ–ç‰‡å¤±æ•—: {e}")
            return []
    
    def image_to_base64(self, image_path):
        """å°‡åœ–ç‰‡è½‰æ›æˆ base64"""
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    
    def ocr_with_vision_api(self, image_path):
        """ä½¿ç”¨ Google Vision REST API é€²è¡Œ OCR"""
        try:
            self.logger.info(f"é–‹å§‹ OCR è™•ç†: {os.path.basename(image_path)}")
            
            url = f"https://vision.googleapis.com/v1/images:annotate?key={self.vision_api_key}"
            image_base64 = self.image_to_base64(image_path)
            
            request_body = {
                "requests": [{
                    "image": {"content": image_base64},
                    "features": [{"type": "DOCUMENT_TEXT_DETECTION"}],
                    "imageContext": {"languageHints": ["zh-TW", "en"]}
                }]
            }
            
            headers = {"Content-Type": "application/json"}
            response = requests.post(url, headers=headers, json=request_body, timeout=60)
            
            if response.status_code == 200:
                result = response.json()
                self.logger.info(f"OCR è™•ç†æˆåŠŸ: {os.path.basename(image_path)}")
                return result
            else:
                self.logger.error(f"Vision API è«‹æ±‚å¤±æ•—: {response.status_code}")
                return None
                
        except Exception as e:
            self.logger.error(f"OCR è™•ç†å¤±æ•—: {e}")
            return None
    
    def is_chinese_char(self, char):
        """åˆ¤æ–·æ˜¯å¦ç‚ºä¸­æ–‡å­—ç¬¦"""
        if not char:
            return False
        return '\u4e00' <= char[0] <= '\u9fff'
    
    def merge_words_intelligently(self, words):
        """æ™ºæ…§åˆä½µå–®è©ï¼Œæ¸›å°‘ä¸å¿…è¦çš„ç©ºæ ¼"""
        if not words:
            return ""
        
        result = []
        i = 0
        
        while i < len(words):
            current_word = words[i]
            
            if len(current_word) == 1 and self.is_chinese_char(current_word):
                combined = current_word
                j = i + 1
                
                while j < len(words) and len(words[j]) <= 2:
                    if self.is_chinese_char(words[j]) or words[j].isalpha():
                        combined += words[j]
                        j += 1
                    else:
                        break
                
                result.append(combined)
                i = j
            else:
                result.append(current_word)
                i += 1
        
        return ' '.join(result)
    
    def process_ocr_with_coordinates(self, ocr_results):
        """è™•ç†OCRçµæœï¼Œä¾æ“šåº§æ¨™é‡çµ„æ®µè½ï¼ˆæ¡ç”¨ç¬¬ä¸€ä»½ä»£ç¢¼çš„æ–¹æ³•ï¼‰"""
        try:
            processed_text = ""
            
            for page_idx, result in enumerate(ocr_results):
                if not result or 'responses' not in result or not result['responses']:
                    continue
                
                response = result['responses'][0]
                
                if "fullTextAnnotation" not in response:
                    continue
                
                full_text = response["fullTextAnnotation"]
                
                if "pages" in full_text:
                    for page in full_text["pages"]:
                        blocks = []
                        
                        if "blocks" in page:
                            for block in page["blocks"]:
                                if "paragraphs" in block:
                                    for paragraph in block["paragraphs"]:
                                        if "boundingBox" in paragraph:
                                            vertices = paragraph["boundingBox"]["vertices"]
                                            y_coord = vertices[0].get("y", 0)
                                            x_coord = vertices[0].get("x", 0)
                                        else:
                                            y_coord = 0
                                            x_coord = 0
                                        
                                        paragraph_text = ""
                                        if "words" in paragraph:
                                            words = []
                                            for word in paragraph["words"]:
                                                if "symbols" in word:
                                                    word_text = ""
                                                    for symbol in word["symbols"]:
                                                        if "text" in symbol:
                                                            word_text += symbol["text"]
                                                    if word_text.strip():
                                                        words.append(word_text.strip())
                                            
                                            if words:
                                                paragraph_text = self.merge_words_intelligently(words)
                                        
                                        blocks.append({
                                            "text": paragraph_text.strip(),
                                            "y": y_coord,
                                            "x": x_coord
                                        })
                        
                        blocks.sort(key=lambda b: (b["y"], b["x"]))
                        
                        page_text = ""
                        for block in blocks:
                            if block["text"]:
                                page_text += block["text"] + "\n"
                        
                        if page_text:
                            processed_text += f"\n=== ç¬¬ {page_idx + 1} é  ===\n{page_text}"
            
            # åŸºæœ¬é è™•ç†
            lines = processed_text.split('\n')
            cleaned_lines = []
            
            for line in lines:
                line = line.strip()
                if line and len(line) > 1:
                    cleaned_lines.append(line)
            
            return '\n'.join(cleaned_lines)
            
        except Exception as e:
            self.logger.error(f"åº§æ¨™è™•ç†å¤±æ•—: {e}")
            return ""
    
    def clean_chinese_spacing(self, text):
        """æ¸…ç†ä¸­æ–‡è©å½™é–“ä¸å¿…è¦çš„ç©ºæ ¼"""
        try:
            cleaned = re.sub(r'([\u4e00-\u9fff])\s+([\u4e00-\u9fff])', r'\1\2', text)
            cleaned = re.sub(r'\s+', ' ', cleaned)
            return cleaned
        except Exception as e:
            self.logger.error(f"æ¸…ç†ä¸­æ–‡ç©ºæ ¼å¤±æ•—: {e}")
            return text
    
    def identify_document_type(self, text, filename):
        """è­˜åˆ¥æ–‡ä»¶é¡å‹ - æ”¹é€²ç‰ˆï¼šå„ªå…ˆè­˜åˆ¥ä¿¡ç”¨å¡å¸³å–®"""
        text_upper = text.upper()
        filename_upper = filename.upper()
        
        # ä¿¡ç”¨å¡å¸³å–®é—œéµå­—ï¼ˆå„ªå…ˆåˆ¤æ–·ï¼‰
        credit_card_keywords = [
            'ä¿¡ç”¨å¡', 'CREDIT CARD', 'æ‡‰ç¹³é‡‘é¡', 'ç¹³æ¬¾æœŸé™', 
            'æœ¬æœŸæ‡‰ç¹³', 'æœ€ä½æ‡‰ç¹³', 'å¸³å–®æœŸé–“', 'æ¶ˆè²»æ˜ç´°',
            'åœ‹å…§æ¶ˆè²»', 'åœ‹å¤–æ¶ˆè²»', 'å¾ªç’°ä¿¡ç”¨', 'é å€Ÿç¾é‡‘'
        ]
        
        # äº¤å‰²æ†‘å–®é—œéµå­—
        trading_keywords = [
            'äº¤å‰²æ†‘å–®', 'è‚¡ç¥¨', 'è­‰åˆ¸', 'å§”è¨—å–®è™Ÿ', 
            'æˆäº¤åƒ¹æ ¼', 'è‚¡æ•¸', 'è­‰äº¤ç¨…'
        ]
        
        # è¨ˆç®—åŒ¹é…åˆ†æ•¸
        credit_score = sum(1 for keyword in credit_card_keywords 
                          if keyword in text_upper or keyword in filename_upper)
        trading_score = sum(1 for keyword in trading_keywords 
                           if keyword in text_upper or keyword in filename_upper)
        
        # æ ¹æ“šåˆ†æ•¸åˆ¤æ–·
        if credit_score > trading_score:
            self.logger.info(f"è­˜åˆ¥ç‚ºä¿¡ç”¨å¡å¸³å–®ï¼ˆåˆ†æ•¸: {credit_score} vs {trading_score}ï¼‰")
            return "ä¿¡ç”¨å¡å¸³å–®"
        elif trading_score > 0:
            self.logger.info(f"è­˜åˆ¥ç‚ºäº¤å‰²æ†‘å–®ï¼ˆåˆ†æ•¸: {trading_score} vs {credit_score}ï¼‰")
            return "äº¤å‰²æ†‘å–®"
        else:
            # é è¨­ç‚ºä¿¡ç”¨å¡å¸³å–®
            self.logger.info("ç„¡æ³•æ˜ç¢ºè­˜åˆ¥ï¼Œé è¨­ç‚ºä¿¡ç”¨å¡å¸³å–®")
            return "ä¿¡ç”¨å¡å¸³å–®"
    
    def identify_bank(self, text):
        """è­˜åˆ¥éŠ€è¡Œé¡å‹"""
        text_upper = text.upper()
        
        for bank_name, patterns in self.bank_patterns.items():
            for pattern in patterns:
                if pattern.upper() in text_upper:
                    self.logger.info(f"è­˜åˆ¥éŠ€è¡Œ: {bank_name}")
                    return bank_name
        
        self.logger.warning("ç„¡æ³•è­˜åˆ¥éŠ€è¡Œï¼Œä½¿ç”¨é€šç”¨æ ¼å¼")
        return "æœªçŸ¥éŠ€è¡Œ"
    
    def gemini_analyze(self, text, bank_name, document_type):
        """
        ä½¿ç”¨ Gemini 2.5 åˆ†ææ–‡å­— - æ¡ç”¨ç¬¬ä¸€ä»½ä»£ç¢¼çš„æˆåŠŸç­–ç•¥
        åŒ…å«ï¼šç°¡æ½” prompt + é‡è©¦æ©Ÿåˆ¶ + å¼·ç¡¬èªæ°£ + æ–‡å­—é•·åº¦å„ªåŒ–
        """
        self.logger.info(f"é–‹å§‹ Gemini åˆ†æï¼Œæ–‡ä»¶é¡å‹: {document_type}")
        
        # ğŸ†• æª¢æŸ¥ä¸¦ç¸®æ¸›æ–‡å­—é•·åº¦ï¼ˆé¿å…è¶…æ™‚ï¼‰
        text = self.truncate_text_if_needed(text, max_chars=15000)
        self.logger.info(f"è™•ç†å¾Œæ–‡å­—é•·åº¦: {len(text)} å­—å…ƒ")
        
        # æ ¹æ“šæ–‡ä»¶é¡å‹é¸æ“‡ prompt
        if document_type == "äº¤å‰²æ†‘å–®":
            prompt_text = self.create_trading_prompt(text)
        else:
            prompt_text = self.create_bill_prompt(text, bank_name)
        
        # ä½¿ç”¨ Gemini 2.5 Flash
        url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent"
        headers = {
            "Content-Type": "application/json",
            "X-goog-api-key": self.gemini_api_key
        }
        
        payload = {
            "contents": [{"parts": [{"text": prompt_text}]}],
            "generationConfig": {
                "responseMimeType": "application/json",
                "temperature": 0.1  # é™ä½æº«åº¦ï¼Œæé«˜ç©©å®šæ€§
            }
        }
        
        # é‡è©¦æ©Ÿåˆ¶ï¼ˆæ¡ç”¨ç¬¬ä¸€ä»½ä»£ç¢¼çš„ç­–ç•¥ï¼‰
        max_retries = 5
        for retry in range(max_retries):
            try:
                # ğŸ†• å¢åŠ  timeout åˆ° 120 ç§’ï¼Œä¸¦åˆ†æ®µè™•ç†
                timeout_seconds = 120 if retry < 2 else 180
                self.logger.info(f"ç¬¬ {retry + 1} æ¬¡å˜—è©¦ï¼Œtimeout: {timeout_seconds} ç§’")
                
                response = requests.post(url, headers=headers, json=payload, timeout=timeout_seconds)
                response.raise_for_status()
                resp_json = response.json()
                
                # æª¢æŸ¥å›æ‡‰
                if 'candidates' not in resp_json or not resp_json['candidates']:
                    self.logger.error("Gemini å›æ‡‰ç‚ºç©ºæˆ–è¢«éæ¿¾")
                    self.logger.error(f"å®Œæ•´å›æ‡‰: {resp_json}")
                    raise Exception("Gemini å›æ‡‰ç‚ºç©º")
                
                generated_text = resp_json["candidates"][0]["content"]["parts"][0]["text"]
                self.logger.info(f"æ”¶åˆ° Gemini å›æ‡‰ï¼Œé•·åº¦: {len(generated_text)} å­—å…ƒ")
                
                # æ¸…ç†ä¸¦è§£æ JSON
                json_text = self.clean_json_response(generated_text)
                
                # ğŸ†• å˜—è©¦è§£æå‰å…ˆé©—è­‰
                try:
                    result = json.loads(json_text)
                except json.JSONDecodeError as json_err:
                    self.logger.error(f"JSON è§£æå¤±æ•—: {json_err}")
                    self.logger.error(f"å•é¡Œ JSON ç‰‡æ®µ: {json_text[max(0, json_err.pos-100):json_err.pos+100]}")
                    
                    # ğŸ†• å˜—è©¦ä¿®å¾©å¸¸è¦‹çš„ JSON å•é¡Œ
                    json_text = self.repair_json(json_text)
                    result = json.loads(json_text)
                
                # æ¨™æº–åŒ–æ ¼å¼
                result = self.normalize_response(result)
                
                self.logger.info(f"âœ… Gemini åˆ†ææˆåŠŸï¼ˆç¬¬ {retry + 1} æ¬¡å˜—è©¦ï¼‰")
                return result
                
            except requests.exceptions.Timeout as e:
                self.logger.warning(f"â±ï¸ Gemini API ç¬¬ {retry + 1} æ¬¡å˜—è©¦è¶…æ™‚: {e}")
                if retry < max_retries - 1:
                    wait_time = 2 ** retry
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                else:
                    self.logger.error("âŒ Gemini åˆ†æå¤±æ•—ï¼šè¶…æ™‚æ¬¡æ•¸éå¤š")
                    
            except json.JSONDecodeError as e:
                self.logger.error(f"âŒ Gemini API ç¬¬ {retry + 1} æ¬¡å˜—è©¦å¤±æ•—ï¼šJSON è§£æéŒ¯èª¤")
                self.logger.error(f"éŒ¯èª¤è©³æƒ…: {e}")
                if retry < max_retries - 1:
                    wait_time = 2 ** retry
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                else:
                    self.logger.error("âŒ Gemini åˆ†æå¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
                    
            except (requests.exceptions.RequestException, KeyError) as e:
                self.logger.warning(f"âŒ Gemini API ç¬¬ {retry + 1} æ¬¡å˜—è©¦å¤±æ•—: {e}")
                if retry < max_retries - 1:
                    wait_time = 2 ** retry
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦...")
                    time.sleep(wait_time)
                else:
                    self.logger.error("âŒ Gemini åˆ†æå¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
        
        return None
    
    def repair_json(self, json_text):
        """
        å˜—è©¦ä¿®å¾©å¸¸è¦‹çš„ JSON æ ¼å¼å•é¡Œ
        """
        self.logger.info("å˜—è©¦ä¿®å¾© JSON æ ¼å¼...")
        
        # 1. ç§»é™¤å°¾éƒ¨é€—è™Ÿï¼ˆtrailing commaï¼‰
        json_text = re.sub(r',\s*}', '}', json_text)
        json_text = re.sub(r',\s*]', ']', json_text)
        
        # 2. ä¿®å¾©æœªé–‰åˆçš„å­—ä¸²ï¼ˆç°¡å–®æƒ…æ³ï¼‰
        # é€™å€‹æ¯”è¼ƒè¤‡é›œï¼Œæš«æ™‚è·³é
        
        # 3. ç§»é™¤è¨»è§£ï¼ˆå¦‚æœæœ‰ï¼‰
        json_text = re.sub(r'//.*?\n', '\n', json_text)
        json_text = re.sub(r'/\*.*?\*/', '', json_text, flags=re.DOTALL)
        
        self.logger.info("JSON ä¿®å¾©å®Œæˆ")
        return json_text
    
    def truncate_text_if_needed(self, text, max_chars=15000):
        """
        å¦‚æœæ–‡å­—å¤ªé•·ï¼Œæ™ºæ…§æˆªæ–·ä»¥é¿å…è¶…æ™‚
        ä¿ç•™é–‹é ­ï¼ˆéŠ€è¡Œè³‡è¨Šï¼‰å’Œä¸­é–“é‡è¦éƒ¨åˆ†ï¼ˆäº¤æ˜“æ˜ç´°ï¼‰
        """
        if len(text) <= max_chars:
            return text
        
        self.logger.warning(f"æ–‡å­—éé•· ({len(text)} å­—å…ƒ)ï¼Œé€²è¡Œæ™ºæ…§æˆªæ–·è‡³ {max_chars} å­—å…ƒ")
        
        # ä¿ç•™å‰ 30% (éŠ€è¡Œè³‡è¨Šã€å¸³å–®è³‡è¨Š)
        head_size = int(max_chars * 0.3)
        head = text[:head_size]
        
        # ä¿ç•™å¾Œ 70% (äº¤æ˜“æ˜ç´°)
        tail_size = max_chars - head_size
        tail = text[-tail_size:]
        
        truncated = head + "\n\n[... ä¸­é–“éƒ¨åˆ†å·²çœç•¥ ...]\n\n" + tail
        
        self.logger.info(f"æˆªæ–·å®Œæˆ: {len(truncated)} å­—å…ƒ")
        return truncated
    
    def create_trading_prompt(self, text):
        """å»ºç«‹äº¤å‰²æ†‘å–®åˆ†ææç¤ºè© - ç°¡æ½”ç‰ˆ"""
        return f"""
åˆ†æä»¥ä¸‹äº¤å‰²æ†‘å–®å…§å®¹ä¸¦æå–é‡è¦è³‡è¨Šï¼š

{text}

ã€åš´æ ¼è¦æ±‚ã€‘
1. åªèƒ½å›å‚³ç´”JSONæ ¼å¼ï¼Œç¦æ­¢ä»»ä½•è§£é‡‹æ–‡å­—
2. ä¸å¯ä½¿ç”¨markdownæ¨™è¨˜å¦‚```json```
3. ç›´æ¥ä»¥{{é–‹å§‹ï¼Œä»¥}}çµæŸ
4. ç¦æ­¢å›å‚³ä»»ä½•"ä»¥ä¸‹æ˜¯"ã€"æ ¹æ“š"ç­‰é–‹é ­èªå¥

å–®ç­†äº¤æ˜“JSONçµæ§‹ï¼š
{{
  "category": "é¡åˆ¥",
  "stock_code": "è‚¡ç¥¨ä»£ç¢¼",
  "stock_name": "è‚¡ç¥¨åç¨±",
  "quantity": æ•¸å­—,
  "price": æ•¸å­—,
  "amount": æ•¸å­—,
  "commission": æ•¸å­—,
  "tax": æ•¸å­—,
  "total_amount": æ•¸å­—
}}

å¤šç­†äº¤æ˜“å›å‚³é™£åˆ—æ ¼å¼ï¼š[{{}}, {{}}, ...]

ç«‹å³å›å‚³JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–å…§å®¹ï¼š
"""
    
    def create_bill_prompt(self, text, bank_name):
        from datetime import datetime
        roc_year = datetime.now().year - 1911  # è‡ªå‹•è¨ˆç®—æ°‘åœ‹å¹´
        return f"""
åˆ†æä»¥ä¸‹ä¿¡ç”¨å¡å¸³å–®å…§å®¹ä¸¦æå–é‡è¦è³‡è¨Šï¼š

{text}

ã€åš´æ ¼è¦æ±‚ã€‘
1. åªèƒ½å›å‚³ç´”JSONæ ¼å¼ï¼Œç¦æ­¢ä»»ä½•è§£é‡‹æ–‡å­—
2. ä¸å¯ä½¿ç”¨markdownæ¨™è¨˜å¦‚```json```
3. ç›´æ¥ä»¥{{é–‹å§‹ï¼Œä»¥}}çµæŸ
4. æ‰€æœ‰æ—¥æœŸæ ¼å¼çµ±ä¸€ç‚ºï¼š{roc_year}/MM/DDï¼ˆæ°‘åœ‹å¹´æ ¼å¼ï¼‰
5. ç¦æ­¢å›å‚³ä»»ä½•"ä»¥ä¸‹æ˜¯"ã€"æ ¹æ“š"ç­‰é–‹é ­èªå¥

JSONçµæ§‹ï¼ˆå¿…é ˆåš´æ ¼éµå®ˆï¼‰ï¼š
{{
  "bank_name": "éŠ€è¡Œåç¨±",
  "card_type": "ä¿¡ç”¨å¡é¡å‹",
  "statement_period": "{roc_year}å¹´MMæœˆ",
  "statement_date": "{roc_year}/MM/DD",
  "payment_due_date": "{roc_year}/MM/DD",
  "previous_balance": "ä¸ŠæœŸæ‡‰ç¹³ç¸½é‡‘é¡ï¼ˆå­—ä¸²ï¼Œä¿ç•™é€—è™Ÿï¼‰",
  "payment_received": "å·²ç¹³æ¬¾é‡‘é¡ï¼ˆå­—ä¸²ï¼Œä¿ç•™é€—è™Ÿå’Œè² è™Ÿï¼‰",
  "current_charges": "æœ¬æœŸé‡‘é¡åˆè¨ˆï¼ˆå­—ä¸²ï¼Œä¿ç•™é€—è™Ÿï¼‰",
  "total_amount_due": "æœ¬æœŸæ‡‰ç¹³ç¸½é‡‘é¡ï¼ˆå­—ä¸²ï¼Œä¿ç•™é€—è™Ÿå’Œå…ƒï¼‰",
  "minimum_payment": "æœ¬æœŸæœ€ä½æ‡‰ç¹³é‡‘é¡ï¼ˆå­—ä¸²ï¼Œä¿ç•™é€—è™Ÿå’Œå…ƒï¼‰",
  "transactions": [
    {{
      "date": "MM/DD",
      "merchant": "å®Œæ•´å•†å®¶åç¨±",
      "amount": "é‡‘é¡ï¼ˆå­—ä¸²ï¼Œä¿ç•™é€—è™Ÿï¼‰",
      "category": "é¡åˆ¥ï¼ˆå¦‚ï¼šé¤é£²ã€è³¼ç‰©ã€ç¹³æ¬¾ã€ç¾é‡‘å›é¥‹ã€åˆ†æœŸæ¶ˆè²»ç­‰ï¼‰"
    }}
  ]
}}

é‡è¦æ ¼å¼è¦æ±‚:
1. æ—¥æœŸæ ¼å¼ï¼š
   - statement_date å’Œ payment_due_date ä½¿ç”¨ï¼š{roc_year}/MM/DD  
   - transactions ä¸­çš„ date ä½¿ç”¨ï¼šMM/DD
   - statement_period ä½¿ç”¨ï¼š{roc_year}å¹´MMæœˆ

2. é‡‘é¡æ ¼å¼ï¼š
   - ä¿ç•™åŸå§‹æ ¼å¼ï¼ˆåŒ…å«é€—è™Ÿï¼‰
   - é€€æ¬¾ã€å›é¥‹ç­‰è² æ•¸è«‹åŠ ä¸Šè² è™Ÿ "-"
   - total_amount_due å’Œ minimum_payment è¦åŠ ä¸Š "å…ƒ"
   - ç¯„ä¾‹ï¼š"2,202"ã€"-21"ã€"4,269 å…ƒ"

3. å•†å®¶åç¨±ï¼š
   - ä¿æŒå®Œæ•´å•†å®¶åç¨±ï¼Œä¸è¦æˆªæ–·
   - ç§»é™¤å¤šé¤˜çš„ç©ºæ ¼
   - å¦‚æœæ˜¯åˆ†æœŸä»˜æ¬¾ï¼Œä¿ç•™å®Œæ•´æè¿°ï¼ˆå¦‚ï¼š"å—éƒ½æ±½è»Šè‚¡ä»½æœ‰é™å…¬å¸å®‰å—æœå‹™ åˆ†03æœŸä¹‹ç¬¬02æœŸ"ï¼‰

4. äº¤æ˜“é¡åˆ¥ï¼ˆcategoryï¼‰ï¼š
   - æ ¹æ“šäº¤æ˜“æ€§è³ªåˆ†é¡ï¼šé¤é£²ã€è³¼ç‰©ã€äº¤é€šã€å¨›æ¨‚ã€ç¹³æ¬¾ã€ç¾é‡‘å›é¥‹ã€åˆ†æœŸæ¶ˆè²»ã€åˆ©æ¯ç­‰
   - å¦‚æœç„¡æ³•åˆ¤æ–·ï¼Œå¡«å…¥ "å…¶ä»–"

5. å…¶ä»–è¦æ±‚:
   - æ‰¾ä¸åˆ°çš„æ¬„ä½å¡«å…¥ç©ºå­—ä¸² "" æˆ– "0"
   - äº¤æ˜“æ˜ç´°è«‹æŒ‰æ—¥æœŸé †åºæ’åˆ—
   - é‡‘é¡ä¸­çš„ç©ºæ ¼è¦ç§»é™¤ï¼ˆå¦‚ "4, 269" â†’ "4,269"ï¼‰

ç«‹å³å›å‚³JSONï¼Œä¸è¦ä»»ä½•å…¶ä»–å…§å®¹ï¼š
"""
    
    def clean_json_response(self, generated_text):
        """æ¸…ç† JSON å›æ‡‰ï¼ˆå¢å¼·ç‰ˆ - è™•ç†å¤šç¨®æ ¼å¼å•é¡Œï¼‰"""
        json_text = generated_text.strip()
        
        self.logger.info(f"åŸå§‹å›æ‡‰é•·åº¦: {len(json_text)} å­—å…ƒ")
        self.logger.debug(f"åŸå§‹å›æ‡‰å‰ 500 å­—å…ƒ: {json_text[:500]}")
        
        # ç§»é™¤ markdown æ¨™è¨˜
        if json_text.startswith('```json'):
            json_text = json_text[7:]
        elif json_text.startswith('```'):
            json_text = json_text[3:]
        if json_text.endswith('```'):
            json_text = json_text[:-3]
        
        json_text = json_text.strip()
        
        # å°‹æ‰¾ JSON é–‹å§‹å’ŒçµæŸï¼ˆæ”¯æ´ç‰©ä»¶å’Œé™£åˆ—ï¼‰
        json_start_obj = json_text.find('{')
        json_start_arr = json_text.find('[')
        json_end_obj = json_text.rfind('}')
        json_end_arr = json_text.rfind(']')
        
        # åˆ¤æ–·æ˜¯ç‰©ä»¶é‚„æ˜¯é™£åˆ—
        if json_start_obj >= 0 and (json_start_arr < 0 or json_start_obj < json_start_arr):
            # JSON ç‰©ä»¶
            if json_end_obj > json_start_obj:
                json_text = json_text[json_start_obj:json_end_obj + 1]
        elif json_start_arr >= 0:
            # JSON é™£åˆ—
            if json_end_arr > json_start_arr:
                json_text = json_text[json_start_arr:json_end_arr + 1]
        
        # ç§»é™¤å¯èƒ½çš„ BOM æ¨™è¨˜
        json_text = json_text.replace('\ufeff', '')
        
        # ç§»é™¤æ§åˆ¶å­—ç¬¦
        json_text = ''.join(char for char in json_text if ord(char) >= 32 or char in '\n\r\t')
        
        self.logger.info(f"æ¸…ç†å¾Œ JSON é•·åº¦: {len(json_text)} å­—å…ƒ")
        self.logger.debug(f"æ¸…ç†å¾Œ JSON å‰ 500 å­—å…ƒ: {json_text[:500]}")
        
        return json_text.strip()
    
    def normalize_date(self, date_str):
        """æ¨™æº–åŒ–æ—¥æœŸæ ¼å¼ç‚º YYYY/MM/DD"""
        if not date_str or date_str == "null":
            return None
        
        try:
            # æ°‘åœ‹å¹´æ ¼å¼ 114/MM/DD
            if re.match(r'^\d{3}/\d{1,2}/\d{1,2}$', date_str):
                parts = date_str.split('/')
                year = int(parts[0]) + 1911
                month = parts[1].zfill(2)
                day = parts[2].zfill(2)
                return f"{year}/{month}/{day}"
            
            # MM/DD æ ¼å¼ï¼ˆå‡è¨­ 2025 å¹´ï¼‰
            elif re.match(r'^\d{1,2}/\d{1,2}$', date_str):
                parts = date_str.split('/')
                month = parts[0].zfill(2)
                day = parts[1].zfill(2)
                return f"2025/{month}/{day}"
            
            # å·²ç¶“æ˜¯ YYYY/MM/DD æ ¼å¼
            elif re.match(r'^\d{4}/\d{1,2}/\d{1,2}$', date_str):
                parts = date_str.split('/')
                year = parts[0]
                month = parts[1].zfill(2)
                day = parts[2].zfill(2)
                return f"{year}/{month}/{day}"
            
            return date_str
            
        except Exception as e:
            self.logger.error(f"æ—¥æœŸæ¨™æº–åŒ–å¤±æ•—: {e}")
            return date_str
    
    def normalize_currency(self, currency_str):
        """æ¨™æº–åŒ–å¹£åˆ¥"""
        if not currency_str:
            return "TWD"
        
        currency_map = {
            'TW': 'TWD',
            'JP': 'JPY',
            'US': 'USD',
            'tw': 'TWD',
            'jp': 'JPY',
            'us': 'USD'
        }
        return currency_map.get(currency_str, currency_str)
    
    def normalize_response(self, data):
        """æ¨™æº–åŒ–å›æ‡‰æ ¼å¼ - è™•ç†ç¬¬ä¸€ä»½ä»£ç¢¼çš„ JSON çµæ§‹"""
        try:
            if not data:
                return data
            
            # ğŸ†• è™•ç†ç¬¬ä¸€ä»½ä»£ç¢¼çš„çµæ§‹ï¼ˆcards æ ¼å¼ï¼‰
            if 'cards' in data and isinstance(data['cards'], list):
                for card in data['cards']:
                    if 'transactions' in card and isinstance(card['transactions'], list):
                        for transaction in card['transactions']:
                            # è™•ç†æ—¥æœŸï¼š114/MM/DD â†’ YYYY/MM/DD
                            if 'date' in transaction and transaction['date']:
                                transaction['date'] = self.convert_roc_to_ad(transaction['date'])
                            
                            # è™•ç†å¹£åˆ¥
                            if 'currency' in transaction and transaction['currency']:
                                transaction['currency'] = self.normalize_currency(transaction['currency'])
                            else:
                                transaction['currency'] = 'TWD'
                            
                            # æ¸…ç†å•†å®¶åç¨±
                            if 'merchant' in transaction and transaction['merchant']:
                                merchant = transaction['merchant'].strip()
                                if merchant.startswith('null '):
                                    merchant = merchant[5:]
                                transaction['merchant'] = ' '.join(merchant.split())
            
            # è™•ç†æ—¥æœŸæ¬„ä½ï¼ˆå¸³å–®è³‡è¨Šï¼‰
            date_fields = ['due_date', 'statement_date']
            for field in date_fields:
                if field in data and data[field]:
                    data[field] = self.convert_roc_to_ad(data[field])
            
            # ğŸ†• å¦‚æœæœ‰ transactions æ¬„ä½ï¼ˆç¬¬äºŒä»½ä»£ç¢¼çš„æ ¼å¼ï¼‰ï¼Œä¹Ÿè™•ç†
            if 'transactions' in data and isinstance(data['transactions'], list):
                for transaction in data['transactions']:
                    if 'date' in transaction and transaction['date']:
                        transaction['date'] = self.convert_roc_to_ad(transaction['date'])
                    
                    if 'currency' in transaction and transaction['currency']:
                        transaction['currency'] = self.normalize_currency(transaction['currency'])
                    else:
                        transaction['currency'] = 'TWD'
                    
                    if 'merchant' in transaction and transaction['merchant']:
                        merchant = transaction['merchant'].strip()
                        if merchant.startswith('null '):
                            merchant = merchant[5:]
                        transaction['merchant'] = ' '.join(merchant.split())
            
            # è™•ç† payment_due_dateï¼ˆç¬¬äºŒä»½ä»£ç¢¼çš„æ¬„ä½ï¼‰
            if 'payment_due_date' in data and data['payment_due_date']:
                data['payment_due_date'] = self.convert_roc_to_ad(data['payment_due_date'])
            
            return data
            
        except Exception as e:
            self.logger.error(f"æ¨™æº–åŒ–å›æ‡‰å¤±æ•—: {e}")
            return data
    
    def convert_roc_to_ad(self, date_str):
        """
        è½‰æ›æ°‘åœ‹å¹´åˆ°è¥¿å…ƒå¹´
        114/MM/DD â†’ 2025/MM/DD
        """
        if not date_str or date_str == "null":
            return None
        
        try:
            # å·²ç¶“æ˜¯è¥¿å…ƒå¹´æ ¼å¼ (YYYY/MM/DD)
            if re.match(r'^\d{4}/\d{1,2}/\d{1,2}$', date_str):
                parts = date_str.split('/')
                year = parts[0]
                month = parts[1].zfill(2)
                day = parts[2].zfill(2)
                return f"{year}/{month}/{day}"
            
            # æ°‘åœ‹å¹´æ ¼å¼ (114/MM/DD æˆ– 114/MM)
            if re.match(r'^\d{3}/\d{1,2}(/\d{1,2})?$', date_str):
                parts = date_str.split('/')
                year = int(parts[0]) + 1911
                month = parts[1].zfill(2)
                
                if len(parts) == 3:
                    day = parts[2].zfill(2)
                    return f"{year}/{month}/{day}"
                else:
                    # åªæœ‰å¹´æœˆï¼Œå›å‚³ YYYY/MM æ ¼å¼
                    return f"{year}/{month}"
            
            # MM/DD æ ¼å¼ï¼ˆå‡è¨­ 2025 å¹´ï¼‰
            if re.match(r'^\d{1,2}/\d{1,2}$', date_str):
                parts = date_str.split('/')
                month = parts[0].zfill(2)
                day = parts[1].zfill(2)
                return f"2025/{month}/{day}"
            
            return date_str
            
        except Exception as e:
            self.logger.error(f"æ—¥æœŸè½‰æ›å¤±æ•—: {e} - åŸå§‹æ—¥æœŸ: {date_str}")
            return date_str
    
    def cleanup_temp_files(self, file_paths):
        """æ¸…ç†æš«å­˜æª”æ¡ˆ"""
        for file_path in file_paths:
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    self.logger.info(f"æ¸…ç†æš«å­˜æª”æ¡ˆ: {os.path.basename(file_path)}")
                except Exception as e:
                    self.logger.error(f"æ¸…ç†æš«å­˜æª”æ¡ˆå¤±æ•—: {e}")
    
    def analyze_by_pages(self, ocr_results, bank_name, document_type):
        """
        åˆ†é åˆ†æç­–ç•¥ï¼šç•¶æ–‡å­—å¤ªé•·æ™‚ï¼Œåˆ†é è™•ç†å¾Œåˆä½µçµæœ
        """
        self.logger.info("æ¡ç”¨åˆ†é åˆ†æç­–ç•¥")
        
        try:
            # ç¬¬ä¸€é é€šå¸¸åŒ…å«å¸³å–®åŸºæœ¬è³‡è¨Š
            first_page_text = self.extract_page_text(ocr_results[0]) if ocr_results else ""
            first_page_text = self.clean_chinese_spacing(first_page_text)
            
            # åˆ†æç¬¬ä¸€é ç²å–åŸºæœ¬è³‡è¨Š
            self.logger.info("åˆ†æç¬¬ä¸€é  - åŸºæœ¬è³‡è¨Š")
            base_result = self.gemini_analyze(first_page_text, bank_name, document_type)
            
            if not base_result:
                raise Exception("ç¬¬ä¸€é åˆ†æå¤±æ•—")
            
            # å¦‚æœåªæœ‰ä¸€é ï¼Œç›´æ¥è¿”å›
            if len(ocr_results) == 1:
                return base_result
            
            # è™•ç†å¾ŒçºŒé é¢çš„äº¤æ˜“æ˜ç´°
            all_transactions = base_result.get('transactions', [])
            
            # æ¯æ¬¡è™•ç† 2-3 é 
            page_batch_size = 2
            for i in range(1, len(ocr_results), page_batch_size):
                batch_end = min(i + page_batch_size, len(ocr_results))
                self.logger.info(f"åˆ†æç¬¬ {i+1}-{batch_end} é  - äº¤æ˜“æ˜ç´°")
                
                # åˆä½µé€™å¹¾é çš„æ–‡å­—
                batch_text = ""
                for j in range(i, batch_end):
                    page_text = self.extract_page_text(ocr_results[j])
                    batch_text += f"\n=== ç¬¬ {j+1} é  ===\n{page_text}"
                
                batch_text = self.clean_chinese_spacing(batch_text)
                
                # åªæå–äº¤æ˜“æ˜ç´°
                batch_result = self.gemini_analyze_transactions_only(batch_text, bank_name)
                
                if batch_result and 'transactions' in batch_result:
                    all_transactions.extend(batch_result['transactions'])
                    self.logger.info(f"å¾ç¬¬ {i+1}-{batch_end} é æå– {len(batch_result['transactions'])} ç­†äº¤æ˜“")
            
            # æ›´æ–°å®Œæ•´çµæœ
            base_result['transactions'] = all_transactions
            self.logger.info(f"âœ… åˆ†é åˆ†æå®Œæˆï¼Œå…± {len(all_transactions)} ç­†äº¤æ˜“")
            
            return base_result
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†é åˆ†æå¤±æ•—: {e}")
            return None
    
    def extract_page_text(self, ocr_result):
        """å¾å–®ä¸€é é¢çš„ OCR çµæœæå–æ–‡å­—"""
        try:
            if not ocr_result or 'responses' not in ocr_result:
                return ""
            
            response = ocr_result['responses'][0]
            
            if 'fullTextAnnotation' in response and 'text' in response['fullTextAnnotation']:
                return response['fullTextAnnotation']['text']
            
            return ""
            
        except Exception as e:
            self.logger.error(f"æå–é é¢æ–‡å­—å¤±æ•—: {e}")
            return ""
    
    def gemini_analyze_transactions_only(self, text, bank_name):
        """
        åªæå–äº¤æ˜“æ˜ç´°çš„ Gemini åˆ†æï¼ˆç”¨æ–¼åˆ†é è™•ç†ï¼‰
        """
        prompt_text = f"""
åˆ†æä»¥ä¸‹ä¿¡ç”¨å¡å¸³å–®é é¢ï¼Œåªæå–äº¤æ˜“æ˜ç´°ï¼š

{text}

ã€åš´æ ¼è¦æ±‚ã€‘
1. åªå›å‚³äº¤æ˜“æ˜ç´°çš„ JSON æ ¼å¼
2. ä¸å¯ä½¿ç”¨ markdown æ¨™è¨˜
3. ç›´æ¥ä»¥ {{ é–‹å§‹

JSON æ ¼å¼ï¼š
{{
  "transactions": [
    {{
      "date": "YYYY/MM/DD",
      "merchant": "å•†å®¶åç¨±",
      "amount": æ•¸å­—,
      "currency": "TWD"
    }}
  ]
}}

ç«‹å³å›å‚³JSONï¼š
"""
        
        url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent"
        headers = {
            "Content-Type": "application/json",
            "X-goog-api-key": self.gemini_api_key
        }
        
        payload = {
            "contents": [{"parts": [{"text": prompt_text}]}],
            "generationConfig": {"responseMimeType": "application/json"}
        }
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=120)
            response.raise_for_status()
            resp_json = response.json()
            
            if 'candidates' in resp_json and resp_json['candidates']:
                generated_text = resp_json["candidates"][0]["content"]["parts"][0]["text"]
                json_text = self.clean_json_response(generated_text)
                result = json.loads(json_text)
                return self.normalize_response(result)
            
            return None
            
        except Exception as e:
            self.logger.error(f"äº¤æ˜“æ˜ç´°åˆ†æå¤±æ•—: {e}")
            return None
